#!/usr/bin/env python3
"""
æ”¹é€²ç‰ˆGemini Visionå°è©±åˆ†æå·¥å…·
é‡å°Manusç¹é«”ä¸­æ–‡å°è©±å„ªåŒ–
"""

import asyncio
import json
import base64
from datetime import datetime
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass

try:
    from google import genai
except ImportError:
    print("âŒ è«‹å®‰è£: pip3 install google-genai")
    exit(1)

@dataclass
class ConversationMessage:
    content: str
    sender: str  # user, assistant, system
    timestamp: str
    confidence: float = 0.9
    message_type: str = "normal"  # normal, question, answer, system

class ImprovedGeminiAnalyzer:
    def __init__(self, api_key="AIzaSyBjQOKRMz0uTGnvDe9CDE5BmAwlY0_rCMw"):
        self.api_key = api_key
        self.client = genai.Client(api_key=api_key)
    
    async def analyze_screenshot(self, image_path):
        """åˆ†æå–®å¼µæˆªåœ–"""
        print(f"ğŸ” åˆ†ææˆªåœ–: {image_path}")
        
        try:
            # è®€å–åœ–ç‰‡
            with open(image_path, 'rb') as f:
                image_data = base64.b64encode(f.read()).decode()
            
            # æ”¹é€²çš„æç¤ºè©
            prompt = """
è«‹ä»”ç´°åˆ†æé€™å¼µManuså°è©±æˆªåœ–ï¼Œæå–æ‰€æœ‰å°è©±å…§å®¹ã€‚

åˆ†æè¦æ±‚ï¼š
1. è­˜åˆ¥æ‰€æœ‰ç¹é«”ä¸­æ–‡å°è©±å…§å®¹
2. å€åˆ†ç”¨æˆ¶å•é¡Œå’ŒAIå›è¦†
3. ä¿æŒåŸå§‹æ–‡å­—ï¼Œä¸è¦ä¿®æ”¹æˆ–ç¿»è­¯
4. æŒ‰å°è©±é †åºæ’åˆ—

è­˜åˆ¥è¦å‰‡ï¼š
- ç”¨æˆ¶å•é¡Œï¼šé€šå¸¸æ˜¯æå•ã€è«‹æ±‚å¹«åŠ©ã€æè¿°å•é¡Œ
- AIå›è¦†ï¼šé€šå¸¸æ˜¯å›ç­”ã€å»ºè­°ã€è§£æ±ºæ–¹æ¡ˆ
- ç³»çµ±æ¶ˆæ¯ï¼šå¦‚"Manus has completed"ç­‰

è¼¸å‡ºæ ¼å¼ï¼š
[ç”¨æˆ¶]: å…·é«”å•é¡Œå…§å®¹
[AI]: å…·é«”å›è¦†å…§å®¹
[ç³»çµ±]: ç³»çµ±æ¶ˆæ¯

è«‹åªè¼¸å‡ºå°è©±å…§å®¹ï¼Œæ¯è¡Œä¸€å€‹æ¶ˆæ¯ï¼Œä¸è¦å…¶ä»–èªªæ˜æ–‡å­—ã€‚
"""
            
            # èª¿ç”¨Gemini
            response = self.client.models.generate_content(
                model="gemini-2.0-flash",
                contents=[
                    prompt,
                    {"mime_type": "image/png", "data": image_data}
                ]
            )
            
            # è§£æå›æ‡‰
            conversations = self._parse_response(response.text)
            
            print(f"  âœ… æå–åˆ° {len(conversations)} æ¢å°è©±")
            for conv in conversations:
                print(f"    [{conv.sender}] {conv.content[:50]}...")
            
            return conversations
            
        except Exception as e:
            print(f"âŒ åˆ†æå¤±æ•—: {e}")
            return []
    
    def _parse_response(self, text):
        """è§£æGeminiå›æ‡‰"""
        conversations = []
        lines = text.strip().split('\n')
        
        for line in lines:
            line = line.strip()
            if not line or line.startswith('```'):
                continue
            
            # è§£æä¸åŒæ ¼å¼
            if line.startswith('[ç”¨æˆ¶]') or line.startswith('[USER]'):
                content = line.split(':', 1)[1].strip() if ':' in line else line[4:].strip()
                if content:
                    conversations.append(ConversationMessage(
                        content=content,
                        sender='user',
                        timestamp=datetime.now().isoformat(),
                        message_type='question'
                    ))
            
            elif line.startswith('[AI]') or line.startswith('[åŠ©æ‰‹]') or line.startswith('[ASSISTANT]'):
                content = line.split(':', 1)[1].strip() if ':' in line else line[4:].strip()
                if content:
                    conversations.append(ConversationMessage(
                        content=content,
                        sender='assistant',
                        timestamp=datetime.now().isoformat(),
                        message_type='answer'
                    ))
            
            elif line.startswith('[ç³»çµ±]') or line.startswith('[SYSTEM]'):
                content = line.split(':', 1)[1].strip() if ':' in line else line[4:].strip()
                if content:
                    conversations.append(ConversationMessage(
                        content=content,
                        sender='system',
                        timestamp=datetime.now().isoformat(),
                        message_type='system'
                    ))
            
            # å¦‚æœæ²’æœ‰æ¨™ç±¤ï¼Œå˜—è©¦æ™ºèƒ½åˆ¤æ–·
            elif len(line) > 10:
                sender, msg_type = self._smart_classify(line)
                conversations.append(ConversationMessage(
                    content=line,
                    sender=sender,
                    timestamp=datetime.now().isoformat(),
                    message_type=msg_type
                ))
        
        return conversations
    
    def _smart_classify(self, text):
        """æ™ºèƒ½åˆ†é¡æ¶ˆæ¯"""
        text_lower = text.lower()
        
        # ç³»çµ±æ¶ˆæ¯é—œéµè©
        system_keywords = ['completed', 'task', 'manus has', 'system', 'ç³»çµ±']
        if any(keyword in text_lower for keyword in system_keywords):
            return 'system', 'system'
        
        # å•é¡Œé—œéµè©
        question_keywords = ['å¦‚ä½•', 'æ€éº¼', 'ä»€éº¼', 'ç‚ºä»€éº¼', 'è«‹å•', 'è«‹å¹«', '?', 'ï¼Ÿ', 'éœ€è¦', 'æƒ³è¦']
        if any(keyword in text for keyword in question_keywords):
            return 'user', 'question'
        
        # å›ç­”é—œéµè©
        answer_keywords = ['æ‚¨å¥½', 'å»ºè­°', 'å¯ä»¥', 'æ‡‰è©²', 'æ ¹æ“š', 'æˆ‘å€‘', 'é€™è£¡', 'ä»¥ä¸‹æ˜¯', 'é¦–å…ˆ']
        if any(keyword in text for keyword in answer_keywords):
            return 'assistant', 'answer'
        
        # é»˜èªç‚ºç”¨æˆ¶æ¶ˆæ¯
        return 'user', 'normal'
    
    def save_analysis(self, conversations, output_file="analysis_result.json"):
        """ä¿å­˜åˆ†æçµæœ"""
        if not conversations:
            print("âŒ æ²’æœ‰å°è©±å¯ä¿å­˜")
            return None
        
        # æº–å‚™æ•¸æ“š
        data = {
            'timestamp': datetime.now().isoformat(),
            'total_messages': len(conversations),
            'statistics': {
                'user_messages': sum(1 for c in conversations if c.sender == 'user'),
                'assistant_messages': sum(1 for c in conversations if c.sender == 'assistant'),
                'system_messages': sum(1 for c in conversations if c.sender == 'system')
            },
            'conversations': [{
                'content': conv.content,
                'sender': conv.sender,
                'message_type': conv.message_type,
                'timestamp': conv.timestamp,
                'confidence': conv.confidence
            } for conv in conversations]
        }
        
        # ä¿å­˜JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜å¯è®€æ ¼å¼
        txt_file = output_file.replace('.json', '.txt')
        with open(txt_file, 'w', encoding='utf-8') as f:
            f.write(f"Manuså°è©±åˆ†æçµæœ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"ğŸ“Š çµ±è¨ˆä¿¡æ¯:\n")
            f.write(f"  ç¸½æ¶ˆæ¯æ•¸: {data['total_messages']}\n")
            f.write(f"  ç”¨æˆ¶æ¶ˆæ¯: {data['statistics']['user_messages']}\n")
            f.write(f"  AIå›è¦†: {data['statistics']['assistant_messages']}\n")
            f.write(f"  ç³»çµ±æ¶ˆæ¯: {data['statistics']['system_messages']}\n\n")
            
            f.write("ğŸ“‹ å°è©±å…§å®¹:\n")
            f.write("-" * 40 + "\n\n")
            
            for i, conv in enumerate(conversations, 1):
                f.write(f"[{i:03d}] {conv.sender.upper()} ({conv.message_type}):\n")
                f.write(f"{conv.content}\n")
                f.write("-" * 40 + "\n\n")
        
        print(f"ğŸ’¾ åˆ†æçµæœå·²ä¿å­˜:")
        print(f"  ğŸ“„ JSON: {output_file}")
        print(f"  ğŸ“‹ æ–‡æœ¬: {txt_file}")
        
        return output_file, txt_file

async def main():
    """ä¸»å‡½æ•¸ - åˆ†æå–®å¼µæˆªåœ–"""
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python3 improved_gemini_analyzer.py <æˆªåœ–è·¯å¾‘>")
        print("ä¾‹å¦‚: python3 improved_gemini_analyzer.py scroll_20250622_193050_000.png")
        return
    
    image_path = sys.argv[1]
    
    if not Path(image_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
        return
    
    analyzer = ImprovedGeminiAnalyzer()
    
    print("ğŸš€ é–‹å§‹åˆ†ææˆªåœ–...")
    conversations = await analyzer.analyze_screenshot(image_path)
    
    if conversations:
        print(f"\nâœ… åˆ†æå®Œæˆï¼æå–åˆ° {len(conversations)} æ¢å°è©±")
        
        # é¡¯ç¤ºçµ±è¨ˆ
        user_count = sum(1 for c in conversations if c.sender == 'user')
        ai_count = sum(1 for c in conversations if c.sender == 'assistant')
        system_count = sum(1 for c in conversations if c.sender == 'system')
        
        print(f"ğŸ“Š çµ±è¨ˆ: ç”¨æˆ¶ {user_count}, AI {ai_count}, ç³»çµ± {system_count}")
        
        # é¡¯ç¤ºå‰å¹¾æ¢
        print(f"\nğŸ“‹ å°è©±é è¦½:")
        for i, conv in enumerate(conversations[:5]):
            print(f"  {i+1}. [{conv.sender}] {conv.content[:60]}...")
        
        # ä¿å­˜çµæœ
        output_file = f"analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        analyzer.save_analysis(conversations, output_file)
        
    else:
        print("âŒ æ²’æœ‰æå–åˆ°å°è©±å…§å®¹")
        print("ğŸ’¡ å»ºè­°æª¢æŸ¥:")
        print("  1. åœ–ç‰‡æ˜¯å¦æ¸…æ™°")
        print("  2. æ˜¯å¦åŒ…å«å°è©±å…§å®¹")
        print("  3. APIå¯†é‘°æ˜¯å¦æ­£ç¢º")

if __name__ == "__main__":
    asyncio.run(main())

